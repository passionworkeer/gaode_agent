# chat_agent_qwen/agent_self/agent.py
import asyncio
from .chat_agent_qwen_3_max import QwenModel
from ..agent_tools.tools import (
    BaseTool,
    SecureCodeInterpreterTool,
    FileRunnerTool,
    TavilySearchTool,
    VisualizationTool,
    FileTool,
)
from ..agent_tools.rag_tool import RAGTool
from ..agent_tools.icl_tool import ICLTool
from ..ICL_agent.icl_agent import ICLAgent
from ..agent_mcp.agent_mcp_gaode import MCPClient
from ..agent_memory.memory import MemoryManager
from ..prompts.system_prompts import TASK_PLANNER_SYSTEM_PROMPT, TOOL_USAGE_GUIDELINES
from ..utils.json_parser import RobustJSONParser
from ..utils.message_validator import MessageValidator
from ..utils.step_context import StepContext, TaskStep, ExecutionStrategy
import logging
from enum import Enum
from pydantic import BaseModel, Field, create_model
import re
import os
import json
from typing import List, Dict, Any, Tuple, Callable, Coroutine, Optional

logger = logging.getLogger(__name__)


class Intent(Enum):
    """ç”¨æˆ·æ„å›¾çš„æšä¸¾ç±»å‹"""
    GENERAL_CHAT = "general_chat"
    TOOL_INFO_QUERY = "tool_info_query"
    KNOWLEDGE_QUERY_ICL = "knowledge_query_icl"
    KNOWLEDGE_QUERY_RAG = "knowledge_query_rag"
    COMPLEX_TASK = "complex_task"


class Agent:
    def __init__(self, model: QwenModel, memory: MemoryManager):
        self.model = model
        self.memory = memory
        self.file_runner = FileRunnerTool()
        self.mcp_client = MCPClient()
        self.visualization_tool = VisualizationTool(llm_model=model, memory_manager=memory)
        self.file_tool = FileTool(llm_model=model, memory_manager=memory)
        self.icl_agent = ICLAgent(model)
        self.icl_tool = ICLTool(self.icl_agent)
        self.tools: Dict[str, BaseTool] = {}
        self.tool_methods: Dict[str, Coroutine] = {} # âœ… æ–°å¢ï¼šå­˜å‚¨ MCP å·¥å…·æ–¹æ³•
        
    async def _register_tools(self) -> None:
        """æ³¨å†Œæ‰€æœ‰å·¥å…·ï¼ˆåŒ…æ‹¬MCPå·¥å…·ï¼‰"""
        # âœ… æ­¥éª¤ 1: è·å– MCP å·¥å…·çš„æ–¹æ³•å’Œå…ƒæ•°æ®
        mcp_tool_methods = await self.mcp_client.get_tool_methods()
        mcp_tools_metadata = await self.mcp_client.get_tools_metadata()

        # âœ… ç›´æ¥å°†MCPæ–¹æ³•æ³¨å†Œåˆ°tool_methodsï¼ˆç”¨äºæ‰§è¡Œï¼‰
        self.tool_methods.update(mcp_tool_methods)
        logger.info(f"âœ… åŠ è½½äº† {len(mcp_tool_methods)} ä¸ª MCP å·¥å…·æ–¹æ³•: {list(mcp_tool_methods.keys())}")

        # âœ… æ­¥éª¤ 2: å°† MCP å…ƒæ•°æ®è½¬æ¢ä¸º BaseTool å…¼å®¹å¯¹è±¡ä»¥ä¾¿ç»Ÿä¸€æè¿°
        mcp_tools_as_basetools = {}
        for meta in mcp_tools_metadata:
            properties_dict = meta.get('parameters', {}).get('properties', {})
            
            # åŠ¨æ€åˆ›å»º Pydantic æ¨¡å‹ä½œä¸º args_schema
            args_fields = {}
            for field_name, field_definition in properties_dict.items(): 
                mcp_type = field_definition.get("type", "string")
                python_type = {
                    "string": str,
                    "integer": int,
                    "number": float,
                    "boolean": bool,
                }.get(mcp_type, str)
                
                description = field_definition.get("description", "")
                args_fields[field_name] = (python_type, Field(..., description=description))

            dynamic_args_model = create_model(
                f"{meta['name']}Args",
                **args_fields
            ) if args_fields else None

            # åˆ›å»º BaseTool å…¼å®¹çš„ç±»
            tool_class = type(
                meta['name'],
                (BaseTool,),
                {
                    'name': meta['name'],
                    'description': meta['description'],
                    'args_schema': dynamic_args_model,
                }
            )
            mcp_tools_as_basetools[meta['name']] = tool_class(
                name=meta['name'], 
                description=meta['description']
            )

        # âœ… æ­¥éª¤ 3: åˆå¹¶æ‰€æœ‰å·¥å…·æè¿°å¯¹è±¡ï¼ˆç”¨äºLLMæŸ¥çœ‹ï¼‰
        self.tools = {
            "web_search": TavilySearchTool(),
            "secure_python_interpreter": SecureCodeInterpreterTool(),
            "run_created_file": self.file_runner,
            "rag_query": RAGTool(),
            "in_context_learning_search": self.icl_tool,
            "visualization_tool": self.visualization_tool,
            "file_tool": self.file_tool,
            **mcp_tools_as_basetools  # åˆå¹¶ MCP å·¥å…·çš„æè¿°å¯¹è±¡
        }
        logger.info(f"âœ… å·¥å…·æè¿°å·²æ³¨å†Œ: {list(self.tools.keys())}")
        logger.info(f"âœ… å·¥å…·æ‰§è¡Œæ–¹æ³•å·²æ³¨å†Œ: {list(self.tool_methods.keys())}")


    def list_tools(self) -> str:
        """è¿”å›æ‰€æœ‰å·¥å…·çš„æè¿°å­—ç¬¦ä¸²ï¼Œä¾›LLMä½¿ç”¨ã€‚"""
        tool_strings = []
        for name, tool in self.tools.items():
            # åŸºç¡€æè¿°
            description = getattr(tool, 'description', 'No description available.')
            tool_str = f"- {name}: {description}"

            # å°è¯•è·å–å¹¶æ ¼å¼åŒ–å‚æ•°
            if hasattr(tool, 'args_schema') and hasattr(tool.args_schema, 'model_fields'):
                params = tool.args_schema.model_fields
                if params:
                    param_details = []
                    for param_name, field_info in params.items():
                        param_desc = getattr(field_info, 'description', '')
                        param_details.append(f"  - {param_name}: {param_desc}")
                    if param_details:
                        tool_str += "\n  å‚æ•°:\n" + "\n".join(param_details)
            tool_strings.append(tool_str)
        
        return "\n".join(tool_strings)

    async def _classify_intent(self, user_input: str, history: List[Dict]) -> Intent:
        """ä½¿ç”¨LLMå¯¹ç”¨æˆ·æ„å›¾è¿›è¡Œåˆ†ç±»"""
        prompt = f"""
[ä»»åŠ¡]
æ ¹æ®ç”¨æˆ·çš„æœ€æ–°æŒ‡ä»¤ï¼Œå°†å…¶åˆ†ç±»åˆ°ä»¥ä¸‹æ„å›¾ä¹‹ä¸€ï¼š

1.  **general_chat**: æ™®é€šé—²èŠã€é—®å€™ã€éåŠŸèƒ½æ€§å¯¹è¯ã€‚
    (ç¤ºä¾‹: "ä½ å¥½", "ä½ å«ä»€ä¹ˆåå­—?", "ä»Šå¤©å¤©æ°”çœŸå¥½")
2.  **tool_info_query**: è¯¢é—®å…³äºAgentèƒ½åŠ›ã€å¯ç”¨å·¥å…·çš„é—®é¢˜ã€‚
    (ç¤ºä¾‹: "ä½ èƒ½åšä»€ä¹ˆ?", "ä½ æœ‰å“ªäº›å·¥å…·?")
3.  **knowledge_query_icl**: å¯ä»¥é€šè¿‡å°‘é‡ç¤ºä¾‹å¿«é€Ÿå›ç­”çš„çŸ¥è¯†æ€§é—®é¢˜ï¼Œé€šå¸¸æ˜¯å…³äºæ¨èæˆ–ç®€å•æ¯”è¾ƒã€‚
    (ç¤ºä¾‹: "æ¨èæ·±åœ³å‘¨æœ«å»å“ªç©?", "å¹¿å·å’Œä¸Šæµ·å“ªä¸ªæ›´é€‚åˆæ—…æ¸¸?")
4.  **knowledge_query_rag**: éœ€è¦ä»æœ¬åœ°çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯çš„é—®é¢˜ã€‚
    (ç¤ºä¾‹: "æ·±åœ³æœ‰å“ªäº›å¿…å»æ™¯ç‚¹?", "ä»‹ç»ä¸€ä¸‹å¤§é¹æ‰€åŸ")
5.  **complex_task**: éœ€è¦æ‰§è¡Œå¤šä¸ªæ­¥éª¤ã€è°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·æ‰èƒ½å®Œæˆçš„å¤æ‚è¯·æ±‚ã€‚
    (ç¤ºä¾‹: "è§„åˆ’ä¸€ä¸ªä»æ·±åœ³åˆ°åŒ—äº¬çš„ä¸‰æ—¥æ¸¸", "å¸®æˆ‘æŸ¥ä¸€ä¸‹ä»æˆ‘å®¶åˆ°å…¬å¸æ€ä¹ˆèµ°ï¼Œå¹¶æŠŠè·¯çº¿å›¾ç”»å‡ºæ¥")

[å†å²å¯¹è¯]
{history[-3:]}

[ç”¨æˆ·æœ€æ–°æŒ‡ä»¤]
"{user_input}"

[è¾“å‡º]
è¯·ä»…è¿”å›æœ€åŒ¹é…çš„æ„å›¾ç±»åˆ«åç§°ï¼ˆä¾‹å¦‚: "complex_task"ï¼‰ã€‚
"""
        response = await self.model.agenerate(prompt)
        intent_str = response.strip().lower()

        try:
            return Intent(intent_str)
        except ValueError:
            logger.warning(f"æœªçŸ¥çš„æ„å›¾: '{intent_str}', é™çº§ä¸º 'complex_task'")
            return Intent.COMPLEX_TASK

    async def _need_tool_use(self, user_input: str, history: List[Dict]) -> bool:
        """(å¼‚æ­¥)åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ã€‚"""
        # å¦‚æœå·¥å…·åˆ—è¡¨ä¸ºç©ºï¼Œå…ˆæ³¨å†Œ
        if not self.tools:
            await self._register_tools()

        prompt = f"""
[å¯ç”¨å·¥å…·]
{self.list_tools()}

[å†å²å¯¹è¯]
{history[-5:]}

[ç”¨æˆ·æœ€æ–°æŒ‡ä»¤]
"{user_input}"

[åˆ¤æ–­ä»»åŠ¡]
æ ¹æ®ç”¨æˆ·çš„æœ€æ–°æŒ‡ä»¤ï¼Œåˆ¤æ–­æ˜¯å¦å¿…é¡»ä½¿ç”¨ä¸Šè¿°ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·æ‰èƒ½å®Œæˆã€‚
- å¦‚æœç”¨æˆ·åœ¨è¿›è¡Œå¸¸è§„èŠå¤©ã€æ‰“æ‹›å‘¼ã€é—®å€™ã€è¡¨è¾¾è§‚ç‚¹ï¼Œè€Œæ²¡æœ‰æå‡ºå…·ä½“çš„æ“ä½œæ€§éœ€æ±‚ï¼Œåˆ™å›ç­” "å¦"ã€‚
- å¦‚æœç”¨æˆ·çš„æŒ‡ä»¤æ˜ç¡®è¦æ±‚æˆ–æš—ç¤ºäº†éœ€è¦è¿›è¡Œæœç´¢ã€è®¡ç®—ã€æŸ¥è¯¢ã€ç”»å›¾ã€æ–‡ä»¶æ“ä½œç­‰ï¼Œåˆ™å›ç­” "æ˜¯"ã€‚
- å¦‚æœç”¨æˆ·çš„æŒ‡ä»¤æ˜¯å…³äºä»£ç æˆ–æ‰§è¡Œä»£ç ï¼Œåˆ™å›ç­” "æ˜¯"ã€‚
- å¦‚æœç”¨æˆ·çš„æŒ‡ä»¤æ˜¯æŸ¥è¯¢å…³äºå·¥å…·æœ¬èº«èƒ½åšä»€ä¹ˆï¼Œåˆ™å›ç­” "å¦"ã€‚

è¯·åªå›ç­” "æ˜¯" æˆ– "å¦"ã€‚
"""
        # ä½¿ç”¨å¼‚æ­¥ç”Ÿæˆæ–¹æ³•
        response = await self.model.agenerate(prompt)
        decision = response.strip()
        logger.info(f"å·¥å…·ä½¿ç”¨å†³ç­–: '{decision}' (åŸå§‹è¾“å‡º: '{response}')")
        return "æ˜¯" in decision

    async def plan_tasks(self, user_input: str, user_id: str) -> List[TaskStep]:
        """å¼‚æ­¥ä»»åŠ¡è§„åˆ’ï¼ˆç¡®ä¿å·¥å…·å·²åŠ è½½ï¼‰"""
        memory = self.memory.load_memory(user_id)
        history = memory["conversation_history"]

        if not self.tools:
            await self._register_tools()

        # âœ… ä½¿ç”¨ list_tools() ç”Ÿæˆæ›´ç®€æ´ã€ç»“æ„åŒ–çš„å·¥å…·åˆ—è¡¨
        system_content = (
            f"{TASK_PLANNER_SYSTEM_PROMPT}\n\n"
            f"{TOOL_USAGE_GUIDELINES}\n\n"
            f"å¯ç”¨å·¥å…·åˆ—è¡¨:\n{self.list_tools()}"
        )
        
        prompt = [
                        {"role": "system", "content": system_content},
                        {"role": "system", "content": """è¾“å‡ºæ ¼å¼: ä¸¥æ ¼ JSON æ•°ç»„,æ¯ä¸ªå¯¹è±¡ä»…åŒ…å« goalã€tool_nameã€parameters ä¸‰ä¸ªå­—æ®µã€‚

ç»å¯¹çº¦æŸ(å¿…é¡»éµå®ˆ,å¦åˆ™æ‰§è¡Œä¼šå¤±è´¥):
1) å·¥å…·åå¿…é¡»ä¸ºå…·ä½“çš„å®˜æ–¹åç§°,ä¾‹å¦‚: maps_geo, maps_direction_driving, maps_direction_walking, maps_direction_bicycling, maps_direction_transit_integrated, maps_text_search, maps_around_search, maps_search_detail, maps_weather, maps_regeocode, maps_ip_location, maps_distance, visualization_tool, file_tool, web_search, rag_query, in_context_learning_searchã€‚
     - ä¸¥ç¦ä½¿ç”¨ä»»ä½•ä¸­ä»‹åˆ«å(å¦‚ mcp_tool)ã€‚ä¸è¦è¾“å‡º {\"tool_name\": \"mcp_tool\"} è¿™æ ·çš„ç»“æ„ã€‚
     - ä¸¥ç¦åœ¨ parameters å†…å†æ¬¡åµŒå¥— {\"tool_name\": ..., \"parameters\": ...}ã€‚
2) å ä½ç¬¦ä»…å…è®¸å­—æ®µ/ä¸‹æ ‡è®¿é—®,æ ¼å¼: {step_N_result.field} æˆ– {step_N_result.array[0].field}ã€‚
     - ä¸¥ç¦ä»»ä½•æ–¹æ³•/å‡½æ•°è°ƒç”¨(ä¾‹å¦‚ .split(), .get(), int(), float() ç­‰)ä¸ä»»ä½•ç®—æœ¯/æ¯”è¾ƒè¿ç®—(+, -, *, /, %, >, < ç­‰)ã€‚
     - å¦‚æœéœ€è¦åæ ‡,é«˜å¾·è¿”å›ç»“æœå·²æä¾›ç‹¬ç«‹å­—æ®µ: lng(ç»åº¦,æµ®ç‚¹æ•°), lat(çº¬åº¦,æµ®ç‚¹æ•°)ã€‚è¯·ç›´æ¥å¼•ç”¨:
             â€¢ {step_0_result.geocodes[0].lng} / {step_0_result.geocodes[0].lat}
             â€¢ {step_1_result.pois[0].lng} / {step_1_result.pois[0].lat}
         è‹¥å·¥å…·éœ€è¦å®Œæ•´åæ ‡å­—ç¬¦ä¸²(å¦‚ maps_direction_* çš„ origin/destination),è¯·å¼•ç”¨å·²æœ‰çš„ location å­—æ®µ:
             â€¢ {step_0_result.geocodes[0].location} æˆ– {step_1_result.pois[0].location}
3) æ­¥éª¤ç´¢å¼•ä» 0 å¼€å§‹,åªèƒ½å¼•ç”¨ä¹‹å‰æ­¥éª¤çš„ç»“æœ(ä¸å¾—å¼•ç”¨å½“å‰æˆ–æœªæ¥æ­¥éª¤)ã€‚

æ­£ç¡®ç¤ºä¾‹:
[
    {"goal": "è·å–æ·±åœ³æŠ€æœ¯å¤§å­¦ç»çº¬åº¦", "tool_name": "maps_geo", "parameters": {"address": "æ·±åœ³æŠ€æœ¯å¤§å­¦"}},
    {"goal": "è§„åˆ’é©¾è½¦è·¯çº¿", "tool_name": "maps_direction_driving", "parameters": {"origin": "{step_0_result.geocodes[0].location}", "destination": "114.029963,22.609185"}},
    {"goal": "ç”Ÿæˆåœ°å›¾", "tool_name": "visualization_tool", "parameters": {"type": "map", "data": {"title": "è·¯çº¿åœ°å›¾", "markers": [{"lng": {step_0_result.geocodes[0].lng}, "lat": {step_0_result.geocodes[0].lat}, "title": "æ·±åœ³æŠ€æœ¯å¤§å­¦"}]}}}
]

é”™è¯¯ç¤ºä¾‹(ç¦æ­¢):
[
    {"tool_name": "mcp_tool", "parameters": {"tool_name": "maps_geo", "parameters": {"address": "æ·±åœ³"}}},
    {"tool_name": "visualization_tool", "parameters": {"data": {"markers": [{"lng": "{step_0_result.pois[0].location.split(',')[0]}", "lat": "{step_0_result.pois[0].location.split(',')[1]}"}]}}}
]
"""},
                ]

        prompt = MessageValidator.safe_extend_history(prompt, history, max_count=3)
        prompt.append({"role": "user", "content": user_input})

        validated_prompt = MessageValidator.validate_messages(prompt)
        response = self.model.generate(validated_prompt).strip()
        
        steps_data = RobustJSONParser.parse(response)

        if not steps_data or not isinstance(steps_data, list):
            logger.warning(f"ä»»åŠ¡è§„åˆ’å¤±è´¥: æ— æ³•è§£æä¸ºåˆ—è¡¨ | è¾“å‡º: {response[:200]}...")
            return []

        try:
            return [TaskStep(**s) for s in steps_data]
        except Exception as e:
            logger.warning(f"ä»»åŠ¡æ­¥éª¤è§£æå¤±è´¥: {e} | æ•°æ®: {steps_data}")
            return []

    async def execute_step(self, step: TaskStep, user_id: str) -> Tuple[bool, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤ï¼Œæ”¯æŒè‡ªå®šä¹‰ MCP å·¥å…·æ–¹æ³•å’Œæ ‡å‡†å·¥å…·"""
        
        # âœ… è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°å½“å‰æ­¥éª¤å’Œå¯ç”¨å·¥å…·
        logger.info(f"ğŸ” å‡†å¤‡æ‰§è¡Œæ­¥éª¤: {step.tool_name}")
        logger.debug(f"ğŸ“‹ å¯ç”¨MCPå·¥å…·æ–¹æ³•: {list(self.tool_methods.keys())}")
        logger.debug(f"ğŸ“‹ å¯ç”¨æ ‡å‡†å·¥å…·: {list(self.tools.keys())}")
        
        # âš ï¸ å‹å¥½æ‹¦æˆª: è‹¥ä»å‡ºç°å†å²åˆ«å mcp_tool, ç›´æ¥ç»™å‡ºæ˜ç¡®é”™è¯¯ä¸æŒ‡å¯¼
        if step.tool_name == "mcp_tool":
            guidance = (
                "æ£€æµ‹åˆ°æ— æ•ˆå·¥å…·å 'mcp_tool'ã€‚è¯·ç›´æ¥ä½¿ç”¨å…·ä½“çš„å®˜æ–¹å·¥å…·å, ä¾‹å¦‚: "
                f"{', '.join(sorted(list(self.tool_methods.keys()))[:8])} ...ã€‚"
                "ä¸è¦åœ¨ parameters å†…å†æ¬¡åµŒå¥— tool_name/parameters; æŒ‰ {tool_name, parameters} ç›´æ¥æä¾›ã€‚"
            )
            logger.error(guidance)
            return False, {"error": guidance}
        
        # âœ… ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦ä¸º MCP å·¥å…·æ–¹æ³•
        if step.tool_name in self.tool_methods:
            target_callable = self.tool_methods[step.tool_name]
            logger.info(f"ğŸ› ï¸ æ‰§è¡Œ MCP å·¥å…·æ–¹æ³•: {step.goal} | å·¥å…·: {step.tool_name} | å‚æ•°: {step.parameters}")
            try:
                result = await target_callable(**step.parameters)
                logger.info(f"âœ… MCP å·¥å…· '{step.tool_name}' æ‰§è¡ŒæˆåŠŸ")
                return True, result
            except Exception as e:
                error_msg = f"MCP å·¥å…· '{step.tool_name}' æ‰§è¡Œé”™è¯¯: {str(e)}"
                logger.error(error_msg, exc_info=True)
                return False, {"error": error_msg}

        # æ£€æŸ¥æ ‡å‡†å·¥å…·
        tool = self.tools.get(step.tool_name)
        if not tool:
            all_available = list(self.tools.keys()) + list(self.tool_methods.keys())
            error_msg = f"âŒ å·¥å…· '{step.tool_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·: {all_available}"
            logger.error(error_msg)
            return False, error_msg

        try:
            logger.info(f"ğŸ› ï¸ æ‰§è¡Œæ ‡å‡†å·¥å…·: {step.goal} | å·¥å…·: {step.tool_name} | å‚æ•°: {step.parameters}")
            
            # --- âœ… ä¿®æ”¹å¼€å§‹ï¼šç¡®ä¿ params æ˜¯å­—å…¸ï¼Œå¹¶æ³¨å…¥ user_id ---
            original_params = step.parameters
            # ç¡®ä¿ params æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°æ·»åŠ  user_id ç­‰é”®å€¼å¯¹
            if isinstance(original_params, dict):
                # ä½¿ç”¨ copy() é¿å…ä¿®æ”¹åŸå§‹ step.parameters (è™½ç„¶é€šå¸¸ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†æ›´å®‰å…¨)
                params = original_params.copy() 
            else:
                # å¦‚æœ params ä¸æ˜¯å­—å…¸ (ä¾‹å¦‚ None, str, list ç­‰)
                # 1. è®°å½•è­¦å‘Šï¼Œå› ä¸ºè¿™å¯èƒ½ä¸æ˜¯é¢„æœŸçš„è¡Œä¸º
                logger.warning(
                    f"æ­¥éª¤ '{step.tool_name}' çš„å‚æ•°ä¸æ˜¯å­—å…¸ç±»å‹ (ç±»å‹: {type(original_params)})ã€‚"
                    f"å°†å°è¯•å°†å…¶ä½œä¸º 'input' å‚æ•°ä¼ é€’ç»™å·¥å…·ï¼Œå¹¶ä¸ºéœ€è¦çš„å·¥å…·æ³¨å…¥ user_idã€‚"
                )
                # 2. åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸æ¥å­˜æ”¾å‚æ•°
                #    - å°†åŸå§‹å‚æ•° (å¦‚æœä¸æ˜¯ None) æ”¾å…¥ 'input' é”®ä¸‹ã€‚
                #    - è¿™æ˜¯ä¸€ç§é€šç”¨çš„å¤„ç†æ–¹å¼ï¼Œä½†å…·ä½“å·¥å…·å¯èƒ½éœ€è¦ä¸åŒçš„å¤„ç†é€»è¾‘ã€‚
                #    - å¯¹äº visualization_tool å’Œ file_toolï¼Œå®ƒä»¬æœŸæœ›çš„æ˜¯æ‰å¹³çš„é”®å€¼å¯¹å‚æ•°ï¼Œ
                #      æ‰€ä»¥æˆ‘ä»¬ä¸»è¦å…³å¿ƒ user_id çš„æ³¨å…¥ã€‚å¦‚æœåŸå§‹å‚æ•°å¾ˆé‡è¦ï¼Œ
                #      å·¥å…·å†…éƒ¨éœ€è¦èƒ½å¤„ç† 'input' é”®ï¼Œæˆ–è€…è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„é€»è¾‘ã€‚
                params = {}
                if original_params is not None:
                    params["input"] = original_params # å¯æ ¹æ®å·¥å…·çº¦å®šè°ƒæ•´é”®å

            # ä¸ºç‰¹å®šå·¥å…·æ³¨å…¥ user_idï¼ˆå¸¦å…œåº•ï¼šCURRENT_USER_ID æˆ– anonymousï¼‰
            if step.tool_name in ["visualization_tool", "file_tool"]:
                effective_uid = (user_id or os.environ.get("CURRENT_USER_ID") or "anonymous")
                if not params.get("user_id"):
                    params["user_id"] = effective_uid
                    logger.debug(f"å·²ä¸ºå·¥å…· '{step.tool_name}' æ³¨å…¥ user_id: {effective_uid}")

            # å¤„ç† ICL tool çš„ç‰¹æ®Šæƒ…å†µ (å¦‚æœé€‚ç”¨)
            # æ³¨æ„ï¼šå¦‚æœ original_params ä¸æ˜¯å­—å…¸ï¼Œè¿™å¯èƒ½ä¸é€‚ç”¨æˆ–éœ€è¦è°ƒæ•´
            if step.tool_name == "in_context_learning_search" and "query" not in params:
                 # æ³¨æ„ï¼šå¦‚æœ step.goal ä¸æ˜¯å­—ç¬¦ä¸²æˆ–ä¸é€‚åˆåš queryï¼Œè¿™é‡Œå¯èƒ½éœ€è¦è°ƒæ•´
                params["query"] = getattr(step, 'goal', '') # ä½¿ç”¨ getattr é¿å… AttributeError
            # --- âœ… ä¿®æ”¹ç»“æŸ ---

            # --- âœ… ä¿®æ”¹ï¼šè°ƒç”¨å·¥å…· ---
            # ç°åœ¨ params è‚¯å®šæ˜¯å­—å…¸äº†ï¼Œå¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ **kwargs è§£åŒ…
            if hasattr(tool, 'arun'):
                raw_result = await tool.arun(**params) # type: ignore
            else:
                # æ³¨æ„ï¼šå¦‚æœ params ä¸æ˜¯å·¥å…· run æ–¹æ³•æœŸæœ›çš„ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œå®ƒæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ
                # ä½†å·¥å…· run æœŸæœ›ä¸€ä¸ªå­—ç¬¦ä¸²æˆ–ä½ç½®å‚æ•°ï¼‰ï¼Œè¿™å¯èƒ½ä¼šå¤±è´¥ã€‚
                # ç†æƒ³æƒ…å†µä¸‹ï¼Œæ‰€æœ‰å·¥å…·éƒ½åº”è¯¥ç»Ÿä¸€ä½¿ç”¨ arun/run å¹¶æ¥å—å­—å…¸å‚æ•°ã€‚
                # è¿™é‡Œæˆ‘ä»¬ä¿æŒåŸé€»è¾‘ï¼Œä½†å¦‚æœ params ç»“æ„å¤æ‚ï¼Œå¯èƒ½éœ€è¦æ›´ç»†è‡´çš„å¤„ç†ã€‚
                raw_result = tool.run(**params)
            # --- âœ… ä¿®æ”¹ç»“æŸ ---

            # --- âœ… ä¿®æ”¹ï¼šç»“æœå¤„ç† ---
            # æ ‡å‡†å·¥å…·å¯èƒ½è¿”å›å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸º JSON
            # ä¹Ÿæœ‰å¯èƒ½ç›´æ¥è¿”å› Python å¯¹è±¡ (dict, list ç­‰)
            if isinstance(raw_result, str):
                try:
                    # å°è¯•è§£æä¸º JSON å¯¹è±¡
                    parsed_result = json.loads(raw_result)
                except (json.JSONDecodeError, TypeError):
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä¿ç•™åŸå§‹å­—ç¬¦ä¸²
                    logger.debug(f"å·¥å…· '{step.tool_name}' è¿”å›çš„å­—ç¬¦ä¸²æ— æ³•è§£æä¸ºJSONï¼Œå°†ä½œä¸ºåŸå§‹å­—ç¬¦ä¸²å¤„ç†ã€‚")
                    parsed_result = raw_result
            else:
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨è¿”å›å€¼
                parsed_result = raw_result

            logger.info(f"âœ… æ ‡å‡†å·¥å…· '{step.tool_name}' æ‰§è¡ŒæˆåŠŸ")
            return True, parsed_result
            # --- âœ… ä¿®æ”¹ç»“æŸ ---
            
        except Exception as e:
            error_msg = f"æ ‡å‡†å·¥å…· '{step.tool_name}' æ‰§è¡Œé”™è¯¯: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return False, {"error": error_msg}

    async def run(
        self, 
        user_input: str, 
        user_id: str = "default", 
        use_icl: bool = False,
        strategy: ExecutionStrategy = ExecutionStrategy.GRACEFUL_DEGRADE,
        stream_callback: Optional[Callable[[str], Coroutine]] = None
    ):
        """æ‰§è¡ŒAgentä¸»æµç¨‹ï¼ˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼Œæ”¯æŒæµå¼è¾“å‡ºï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            use_icl: æ˜¯å¦ä½¿ç”¨ICL
            strategy: æ‰§è¡Œç­–ç•¥ (å¤±è´¥å¤„ç†æ–¹å¼)
            stream_callback: ç”¨äºæµå¼è¾“å‡ºçš„å¼‚æ­¥å›è°ƒå‡½æ•°ï¼ˆå·²åºŸå¼ƒï¼Œç°åœ¨ç›´æ¥ yieldï¼‰
        
        Yields:
            str: æµå¼è¾“å‡ºçš„æ–‡æœ¬ç‰‡æ®µ
        """
        full_response = ""
        
        try:
            # âœ… ç¡®ä¿å·¥å…·å·²å¼‚æ­¥æ³¨å†Œï¼ˆåŒ…æ‹¬MCPï¼‰
            if not self.tools:
                await self._register_tools()
                logger.info(f"âœ… å·²æ³¨å†Œ {len(self.tools)} ä¸ªå·¥å…·")
            
            self.memory.update_history(user_id, {"role": "user", "content": user_input})
            memory = self.memory.load_memory(user_id)

            # 1. æ„å›¾åˆ†ç±»
            intent = await self._classify_intent(user_input, memory["conversation_history"])
            chunk = f"ğŸ” æ„å›¾åˆ†æå®Œæˆ: **{intent.value}**\n\n"
            full_response += chunk
            yield chunk

            # 2. æ ¹æ®æ„å›¾æ‰§è¡Œä¸åŒé€»è¾‘
            if intent == Intent.GENERAL_CHAT:
                # æ„å»ºç”¨äºæ™®é€šèŠå¤©çš„ Prompt
                memory = self.memory.load_memory(user_id)
                history = memory["conversation_history"]
                
                # ä½¿ç”¨ ICL Agent çš„ç¤ºä¾‹ï¼ˆå¦‚æœå¯ç”¨ä¸”æœ‰ç¤ºä¾‹ï¼‰
                icl_examples = ""
                if use_icl and self.icl_agent.examples:
                    icl_examples = "\n\n".join([f"ç¤ºä¾‹ {i+1}:\nç”¨æˆ·: {ex['query']}\nåŠ©æ‰‹: {ex['response']}" for i, ex in enumerate(self.icl_agent.examples)])
                
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä¸ç”¨æˆ·è‡ªç„¶å¯¹è¯ã€‚
            {icl_examples}
            """
                # æ„å»º Messages
                messages = [{"role": "system", "content": system_prompt}]
                messages = MessageValidator.safe_extend_history(messages, history, max_count=5)
                messages.append({"role": "user", "content": user_input})
                validated_messages = MessageValidator.validate_messages(messages)

                # è°ƒç”¨æ¨¡å‹æµå¼ç”Ÿæˆ
                response_generator = self.model.stream_generate(validated_messages) 
                
                # æµå¼è¾“å‡º
                if hasattr(response_generator, '__aiter__'):
                    async for chunk in response_generator:
                        full_response += chunk
                        yield chunk
                elif hasattr(response_generator, '__iter__'):
                    for chunk in response_generator:
                        full_response += chunk
                        yield chunk
                else:
                    # å¦‚æœä¸æ˜¯ç”Ÿæˆå™¨ï¼Œç›´æ¥è¾“å‡º
                    chunk = str(response_generator)
                    full_response += chunk
                    yield chunk
                    
                self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                return

            if intent == Intent.TOOL_INFO_QUERY:
                reply = "æˆ‘å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n" + self.list_tools()
                full_response += reply
                yield reply
                self.memory.update_history(user_id, {"role": "assistant", "content": reply})
                return

            if intent == Intent.KNOWLEDGE_QUERY_ICL:
                chunk = "å¥½çš„ï¼Œæˆ‘å°†ä½¿ç”¨æˆ‘çš„çŸ¥è¯†åº“ä¸ºæ‚¨å¿«é€Ÿè§£ç­”...\n\n"
                full_response += chunk
                yield chunk
                tool = self.tools["in_context_learning_search"]
                result = await tool.arun(query=user_input)
                result_str = str(result)
                full_response += result_str
                yield result_str
                self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                return

            if intent == Intent.KNOWLEDGE_QUERY_RAG:
                chunk = "æ­£åœ¨æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“...\n\n"
                full_response += chunk
                yield chunk
                tool = self.tools["rag_query"]
                result = await tool.arun(query=user_input)
                result_str = str(result)
                full_response += result_str
                yield result_str
                self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                return

            # --- é»˜è®¤æ‰§è¡Œå¤æ‚ä»»åŠ¡é€»è¾‘ ---
            chunk = "å¥½çš„ï¼Œè¯·ç¨ç­‰ï¼Œæˆ‘æ­£åœ¨æ€è€ƒå¦‚ä½•å¤„ç†æ‚¨çš„è¯·æ±‚...\n\n"
            full_response += chunk
            yield chunk

            steps = await self.plan_tasks(user_input, user_id)
            if not steps:
                reply = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨çš„è¯·æ±‚è§„åˆ’å‡ºæœ‰æ•ˆçš„æ‰§è¡Œæ­¥éª¤ã€‚è¯·å°è¯•æ¢ä¸€ç§æ–¹å¼æé—®ï¼Œæˆ–è€…æè¿°å¾—æ›´å…·ä½“ä¸€äº›ã€‚"
                full_response += reply
                yield reply
                self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                return

            chunk = "æˆ‘å·²ç»åˆ¶å®šäº†å¦‚ä¸‹è®¡åˆ’ï¼š\n"
            full_response += chunk
            yield chunk
            for i, step in enumerate(steps):
                chunk = f"   - æ­¥éª¤ {i+1}: {step.goal}\n"
                full_response += chunk
                yield chunk
            chunk = "\nç°åœ¨ï¼Œæˆ‘å°†å¼€å§‹æ‰§è¡Œè¿™äº›æ­¥éª¤...\n\n"
            full_response += chunk
            yield chunk

            step_context = StepContext()
            steps_results = []
            
            for i, step in enumerate(steps):
                chunk = f"**æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {i+1}: {step.goal}**\n"
                full_response += chunk
                yield chunk
                try:
                    resolved_params = step_context.replace_placeholders(step.parameters, i)
                    resolved_step = TaskStep(goal=step.goal, tool_name=step.tool_name, parameters=resolved_params)
                    logger.info(f"æ­¥éª¤ {i}: {step.goal} | è§£æåå‚æ•°: {resolved_params}")
                    chunk = f"   - è°ƒç”¨å·¥å…·: `{step.tool_name}`\n"
                    full_response += chunk
                    yield chunk
                    chunk = f"   - æä¾›å‚æ•°: `{json.dumps(resolved_params, ensure_ascii=False, indent=2)}`\n"
                    full_response += chunk
                    yield chunk
                except ValueError as e:
                    error_msg = f"å‚æ•°è§£æå¤±è´¥: {e}"
                    logger.error(f"æ­¥éª¤ {i} {error_msg}")
                    chunk = f"   - âŒ **é”™è¯¯**: {error_msg}\n"
                    full_response += chunk
                    yield chunk
                    if strategy == ExecutionStrategy.FAIL_FAST:
                        final_reply = f"æŠ±æ­‰ï¼Œä»»åŠ¡åœ¨'{step.goal}'æ­¥éª¤ä¸­æ–­ï¼Œå› ä¸ºå‚æ•°å‡†å¤‡å¤±è´¥ã€‚"
                        full_response += f"\n{final_reply}"
                        yield f"\n{final_reply}"
                        self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                        return
                    success, result = False, {"error": error_msg}
                    resolved_step = step
                else:
                    success, result = await self.execute_step(resolved_step, user_id)
                
                if not success:
                    error_msg = f"æ­¥éª¤ {i+1} æ‰§è¡Œå¤±è´¥: {result}"
                    logger.error(error_msg)
                    chunk = f"   - âŒ **é”™è¯¯**: {result}\n\n"
                    full_response += chunk
                    yield chunk
                    if strategy == ExecutionStrategy.FAIL_FAST:
                        reply = f"æŠ±æ­‰ï¼Œåœ¨æ‰§è¡Œ'{step.goal}'æ—¶é‡åˆ°é—®é¢˜ï¼š{result}\n\nè¯·å°è¯•é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚"
                        full_response += reply
                        yield reply
                        self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
                        return
                    elif strategy == ExecutionStrategy.GRACEFUL_DEGRADE:
                        logger.info(f"æ­¥éª¤å¤±è´¥ï¼Œé™çº§ä¸ºçº¯å¯¹è¯æ¨¡å¼")
                        chunk = "å“å‘€ï¼Œæ‰§è¡Œè®¡åˆ’é‡åˆ°äº†ä¸€ç‚¹å°é—®é¢˜ã€‚æˆ‘å°†å°è¯•æ ¹æ®ç°æœ‰ä¿¡æ¯ä¸ºæ‚¨æ€»ç»“å›ç­”ã€‚\n"
                        full_response += chunk
                        yield chunk
                        break
                
                try:
                    if isinstance(result, str):
                        result_dict = RobustJSONParser.parse(result)
                        step_context.set_result(i, result_dict if result_dict and isinstance(result_dict, dict) else {"raw": result, "success": success})
                    else:
                        step_context.set_result(i, result if isinstance(result, dict) else {"raw": str(result), "success": success})
                    logger.info(f"âœ… æ­¥éª¤ {i} ç»“æœå·²ä¿å­˜")
                    chunk = f"   - âœ… **æˆåŠŸ**: æ­¥éª¤å®Œæˆï¼Œç»“æœå·²ä¿å­˜ã€‚\n\n"
                    full_response += chunk
                    yield chunk
                except Exception as parse_error:
                    logger.warning(f"âš ï¸ æ­¥éª¤ {i} ç»“æœä¿å­˜å¤±è´¥: {parse_error}, ä¿å­˜åŸå§‹å€¼")
                    step_context.set_result(i, {"raw": str(result), "success": success, "error": str(parse_error)})
                    chunk = f"   - âš ï¸ **è­¦å‘Š**: æ­¥éª¤ç»“æœä¿å­˜æ—¶é‡åˆ°é—®é¢˜: {parse_error}\n\n"
                    full_response += chunk
                    yield chunk

                steps_results.append((resolved_step, result))
                self.memory.update_history(user_id, {"role": "system", "content": f"æ‰§è¡Œæ­¥éª¤ {i}: {step.goal}\nå·¥å…·: {step.tool_name}\nç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}"})

            chunk = "æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæ¯•ï¼Œç°åœ¨æˆ‘å°†ä¸ºæ‚¨æ•´åˆæœ€ç»ˆç»“æœ...\n\n---\n\n"
            full_response += chunk
            yield chunk
            
            # è°ƒç”¨ç»“æœæ•´åˆæ–¹æ³•ï¼ˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼‰
            async for chunk in self.integrate_results_stream(user_input, steps_results, user_id):
                full_response += chunk
                yield chunk

            self.memory.update_history(user_id, {"role": "assistant", "content": full_response})

        except Exception as e:
            logger.error(f"Agent ä¸»æµç¨‹å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
            error_message = f"\n\n--- \n**ç³»ç»Ÿé”™è¯¯** \næŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€ä¸ªæ„å¤–çš„é—®é¢˜: `{str(e)}` \nè¯·ç¨åå†è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚"
            full_response += error_message
            yield error_message
            # ç¡®ä¿å³ä½¿åœ¨é¡¶å±‚å¼‚å¸¸ä¸­ï¼Œæœ€ç»ˆçš„é”™è¯¯ä¿¡æ¯ä¹Ÿè¢«è®°å½•
            self.memory.update_history(user_id, {"role": "assistant", "content": full_response})
    
    async def integrate_results_stream(
        self, 
        user_input: str, 
        steps_results: List[Tuple[TaskStep, Any]], 
        user_id: str
    ):
        """æ•´åˆæ‰€æœ‰æ­¥éª¤ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆå›å¤ï¼ˆæµå¼è¾“å‡ºï¼‰
        
        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            steps_results: æ‰€æœ‰æ­¥éª¤çš„æ‰§è¡Œç»“æœåˆ—è¡¨ [(TaskStep, result), ...]
            user_id: ç”¨æˆ·ID
        
        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        try:
            # âœ… æ­¥éª¤ 1: æå–å…³é”®ä¿¡æ¯
            extracted_data = self._extract_key_information(steps_results)
            
            # âœ… æ­¥éª¤ 2: æ„å»ºæ•´åˆæç¤ºè¯
            from ..prompts.system_prompts import RESULT_INTEGRATION_SYSTEM_PROMPT
            
            # å°†æ­¥éª¤ç»“æœæ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬
            steps_summary = []
            for i, (step, result) in enumerate(steps_results):
                steps_summary.append(f"æ­¥éª¤ {i+1}: {step.goal}")
                steps_summary.append(f"å·¥å…·: {step.tool_name}")
                
                # æ ¼å¼åŒ–ç»“æœ
                if isinstance(result, dict):
                    result_str = json.dumps(result, ensure_ascii=False, indent=2)
                else:
                    result_str = str(result)
                
                steps_summary.append(f"ç»“æœ: {result_str[:500]}...")  # é™åˆ¶é•¿åº¦
                steps_summary.append("---")
            
            steps_text = "\n".join(steps_summary)
            
            # è·å–å†å²å¯¹è¯
            memory = self.memory.load_memory(user_id)
            history = memory["conversation_history"]
            
            # âœ… æ­¥éª¤ 3: æ„å»ºå¢å¼ºçš„æ•´åˆæç¤º
            integration_prompt = self._build_integration_prompt(
                user_input, 
                steps_text, 
                extracted_data
            )
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": RESULT_INTEGRATION_SYSTEM_PROMPT},
                {"role": "user", "content": integration_prompt}
            ]
            
            # æ·»åŠ éƒ¨åˆ†å†å²ä¸Šä¸‹æ–‡ï¼ˆæœ€å¤‡2è½®ï¼‰
            messages = MessageValidator.safe_extend_history(messages, history, max_count=2)
            
            # éªŒè¯æ¶ˆæ¯
            validated_messages = MessageValidator.validate_messages(messages)
            
            # æµå¼ç”Ÿæˆæœ€ç»ˆå›å¤ï¼ˆåŒæ—¶æ”¶é›†æ­£æ–‡ç”¨äºåç»­åˆ¤æ–­æ˜¯å¦éœ€è¦å…œåº•è¿½åŠ ï¼‰
            generated_chunks: List[str] = []
            async for chunk in self.model.astream_generate(validated_messages):
                generated_chunks.append(str(chunk))
                yield chunk
            
            # âœ… æ­¥éª¤ 4: åœ¨æµå¼è¾“å‡ºåè¿½åŠ èµ„æºï¼šæ–‡ä»¶ã€åœ°å›¾ã€å›¾ç‰‡ï¼ˆä»…åœ¨æ­£æ–‡æœªåŒ…å«æ—¶å…œåº•è¿½åŠ ï¼‰
            body_text = "".join(generated_chunks)
            has_appended_header = False

            # 4.1 è¿½åŠ æ–‡ä»¶é“¾æ¥
            if extracted_data.get("file_paths"):
                yield "\n\n---\n\n"
                has_appended_header = True
                yield "ğŸ“„ **ç”Ÿæˆçš„æ–‡ä»¶**:\n\n"
                for file_info in extracted_data["file_paths"]:
                    file_type = file_info.get("type", "æ–‡ä»¶")
                    file_path = file_info.get("path", "")
                    if file_path:
                        yield f"- [{file_type}]({file_path})\n"
                        logger.info(f"âœ… æ·»åŠ æ–‡ä»¶é“¾æ¥: {file_path}")

            # 4.2 è¿½åŠ åœ°å›¾ HTML é“¾æ¥
            if extracted_data.get("map_paths"):
                if not has_appended_header:
                    yield "\n\n---\n\n"
                    has_appended_header = True
                # è‹¥æ­£æ–‡ä¸­å°šæœªåŒ…å«åœ°å›¾é“¾æ¥ï¼Œå†è¿½åŠ å…œåº•
                body_has_map = False
                for map_path in extracted_data["map_paths"]:
                    if isinstance(map_path, str) and map_path in body_text:
                        body_has_map = True
                        break
                if not body_has_map:
                    yield "ğŸ—ºï¸ **åœ°å›¾**:\n\n"
                    for idx, map_path in enumerate(extracted_data["map_paths"], start=1):
                        if isinstance(map_path, str) and map_path.endswith(".html"):
                            yield f"- [æ‰“å¼€åœ°å›¾ {idx}]({map_path})\n"
                            logger.info(f"âœ… æ·»åŠ åœ°å›¾é“¾æ¥: {map_path}")

            # 4.3 è¿½åŠ å›¾ç‰‡é¢„è§ˆï¼ˆMarkdown å¤šå›¾ï¼‰
            if extracted_data.get("images"):
                if not has_appended_header:
                    yield "\n\n---\n\n"
                    has_appended_header = True
                # è‹¥æ­£æ–‡ä¸­å·²ç»åŒ…å«å›¾ç‰‡ï¼ˆé€šè¿‡ Markdown ![]() æˆ–åŒ…å«å·²çŸ¥ URLï¼‰åˆ™ä¸å†å…œåº•
                body_has_inline_image = ("![" in body_text) or any(
                    isinstance(u, str) and u in body_text for u in extracted_data["images"]
                )
                if not body_has_inline_image:
                    yield "ğŸ–¼ï¸ **å›¾ç‰‡é¢„è§ˆ**:\n\n"
                    # æ”¯æŒæ¯ä¸ªæ™¯ç‚¹å¤šå¼ å›¾ç‰‡ï¼ˆå‡å®š images ä¸ºæ‰€æœ‰å›¾ç‰‡ï¼Œåˆ†ç»„é€»è¾‘å¯åç»­å¢å¼ºï¼‰
                    for i, url in enumerate(extracted_data["images"][:10], start=1):
                        if isinstance(url, str) and url.startswith("http"):
                            yield f"- å›¾ç‰‡ {i}: {url}\n"
                            yield f"![å›¾ç‰‡ {i}]({url})\n"
                            logger.info(f"âœ… å…œåº•è¿½åŠ å›¾ç‰‡URL: {url}")
                
        except Exception as e:
            logger.error(f"ç»“æœæ•´åˆå¤±è´¥: {e}", exc_info=True)
            yield f"\n\nâš ï¸ æ•´åˆç»“æœæ—¶é‡åˆ°é—®é¢˜: {str(e)}\n\n"
            yield "ä¸è¿‡ï¼Œæ ¹æ®æ‰§è¡Œçš„æ­¥éª¤ï¼Œæˆ‘å¯ä»¥å‘Šè¯‰æ‚¨ï¼š\n"
            
            # é™çº§æ–¹æ¡ˆï¼šç®€å•åˆ—å‡ºç»“æœ
            for i, (step, result) in enumerate(steps_results):
                yield f"\n{i+1}. {step.goal}: "
                if isinstance(result, dict) and "error" not in result:
                    yield "âœ… æˆåŠŸ"
                else:
                    yield "âš ï¸ éƒ¨åˆ†å®Œæˆ"
    
    def _extract_key_information(self, steps_results: List[Tuple[TaskStep, Any]]) -> Dict[str, Any]:
        """ä»æ­¥éª¤ç»“æœä¸­æå–å…³é”®ä¿¡æ¯
        
        Args:
            steps_results: æ‰€æœ‰æ­¥éª¤çš„æ‰§è¡Œç»“æœ
            
        Returns:
            åŒ…å«æå–ä¿¡æ¯çš„å­—å…¸
        """
        extracted = {
            "weather_data": [],
            "file_paths": [],
            "map_paths": [],
            "routes": [],
            "pois": [],
            "images": [],
            "web_search_images": [],  # [{query, image_urls}]
            "poi_images": {}          # {poi_name: [urls]}
        }
        
        for step, result in steps_results:
            tool_name = step.tool_name
            
            # âœ… æå–å¤©æ°”æ•°æ®
            if tool_name == "maps_weather" and isinstance(result, dict):
                if "forecasts" in result:
                    extracted["weather_data"].extend(result["forecasts"])
                    logger.info(f"âœ… æå–å¤©æ°”æ•°æ®: {len(result['forecasts'])} æ¡")
            
            # âœ… æå–æ–‡ä»¶è·¯å¾„
            elif tool_name == "file_tool" and isinstance(result, str):
                # file_tool è¿”å›çš„æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
                if result and not result.startswith("é”™è¯¯"):
                    file_type = "è¡Œç¨‹æ–‡æ¡£"
                    if ".html" in result:
                        file_type = "HTMLæ–‡æ¡£"
                    elif ".pdf" in result:
                        file_type = "PDFæ–‡æ¡£"
                    elif ".xlsx" in result or ".xls" in result:
                        file_type = "Excelè¡¨æ ¼"
                    
                    extracted["file_paths"].append({
                        "type": file_type,
                        "path": result
                    })
                    logger.info(f"âœ… æå–æ–‡ä»¶è·¯å¾„: {result}")
            
            # âœ… æå–åœ°å›¾è·¯å¾„
            elif tool_name == "visualization_tool" and isinstance(result, str):
                if result and result.endswith(".html") and not result.startswith("é”™è¯¯"):
                    extracted["map_paths"].append(result)
                    logger.info(f"âœ… æå–åœ°å›¾è·¯å¾„: {result}")
            
            # âœ… æå–è·¯çº¿ä¿¡æ¯
            elif "direction" in tool_name and isinstance(result, dict):
                if "paths" in result or "route" in result:
                    extracted["routes"].append({
                        "tool": tool_name,
                        "data": result
                    })
                    logger.info(f"âœ… æå–è·¯çº¿ä¿¡æ¯: {tool_name}")
            
            # âœ… æå– POI ä¿¡æ¯
            elif tool_name == "maps_text_search" and isinstance(result, dict):
                if "pois" in result:
                    extracted["pois"].extend(result["pois"][:5])  # åªå–å‰5ä¸ª
                    logger.info(f"âœ… æå– POI ä¿¡æ¯: {len(result['pois'])} ä¸ª")
            
            # âœ… æå–æœç´¢ç»“æœä¸­çš„å›¾ç‰‡ URL
            elif tool_name == "web_search":
                # 1) ä¼˜å…ˆä»ç»“æ„åŒ–å­—æ®µæå–ï¼ˆæ¨èè·¯å¾„ï¼‰
                if isinstance(result, dict):
                    image_urls = result.get("image_urls") or []
                    # è®°å½• query ä¸å›¾ç‰‡çš„æ˜ å°„ï¼Œä¾¿äºåç»­æŒ‰æ™¯ç‚¹ç»‘å®š
                    try:
                        query_text = ""
                        if isinstance(step.parameters, dict):
                            query_text = step.parameters.get("query", "") or ""
                    except Exception:
                        query_text = ""
                    if isinstance(image_urls, list) and image_urls:
                        # æœ€å¤šä¿ç•™ 5 å¼ 
                        urls = [u for u in image_urls[:5] if isinstance(u, str)]
                        extracted["images"].extend(urls)
                        if query_text:
                            extracted["web_search_images"].append({
                                "query": query_text,
                                "image_urls": urls
                            })
                        logger.info(f"âœ… ä» web_search.image_urls æå–å›¾ç‰‡: {len(urls)} å¼  | query='{query_text[:40]}'")
                    if isinstance(image_urls, list) and image_urls:
                        pass
                # 2) å…¼å®¹æ—§è·¯å¾„ï¼šä»å­—ç¬¦ä¸²ç»“æœä¸­ç”¨æ­£åˆ™æå–
                elif isinstance(result, str):
                    import re
                    image_urls = re.findall(r'https?://[^\s<>"]+?\.(?:jpg|jpeg|png|gif|webp)', result)
                    if image_urls:
                        extracted["images"].extend(image_urls[:3])  # æœ€å¤š3å¼ 
                        logger.info(f"âœ… ä»å­—ç¬¦ä¸²ç»“æœæå–å›¾ç‰‡ URL: {len(image_urls)} ä¸ª")

        # åŸºäº web_search çš„ query ç²—ç•¥å°†å›¾ç‰‡ç»‘å®šåˆ° POIï¼ˆæŒ‰åç§°åŒ…å«å…³ç³»ï¼‰
        try:
            poi_names = []
            for poi in extracted.get("pois", []) or []:
                name = poi.get("name") or poi.get("title")
                if isinstance(name, str) and name:
                    poi_names.append(name)
            if poi_names and extracted.get("web_search_images"):
                for pair in extracted["web_search_images"]:
                    q = (pair.get("query") or "").lower()
                    urls = pair.get("image_urls") or []
                    if not q or not urls:
                        continue
                    # æ‰¾åˆ°åç§°ä¸ query äº’ä¸ºåŒ…å«çš„ POI
                    target = None
                    for pn in poi_names:
                        pn_l = pn.lower()
                        if pn_l in q or q in pn_l:
                            target = pn
                            break
                    if target:
                        bucket = extracted["poi_images"].setdefault(target, [])
                        for u in urls:
                            if isinstance(u, str) and u not in bucket:
                                bucket.append(u)
        except Exception as e:
            logger.warning(f"âš ï¸ ç»‘å®šå›¾ç‰‡åˆ° POI æ˜ å°„æ—¶å‘ç”Ÿé—®é¢˜: {e}")
        
        return extracted
    
    def _build_integration_prompt(
        self, 
        user_input: str, 
        steps_text: str, 
        extracted_data: Dict[str, Any]
    ) -> str:
        """æ„å»ºå¢å¼ºçš„æ•´åˆæç¤º
        
        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            steps_text: æ­¥éª¤æ‰§è¡Œç»“æœæ–‡æœ¬
            extracted_data: æå–çš„å…³é”®ä¿¡æ¯
            
        Returns:
            æ•´åˆæç¤ºè¯
        """
        prompt_parts = [
            f"[ç”¨æˆ·åŸå§‹é—®é¢˜]",
            user_input,
            "",
            f"[æ‰§è¡Œæ­¥éª¤åŠç»“æœ]",
            steps_text,
            "",
            f"[ä»»åŠ¡]",
            "è¯·åŸºäºä»¥ä¸Šæ­¥éª¤çš„æ‰§è¡Œç»“æœï¼Œç”Ÿæˆä¸€ä¸ªè¿è´¯ã€è‡ªç„¶ã€ä¿¡æ¯å®Œæ•´ä¸”å¯ç›´æ¥æ¸²æŸ“çš„ Markdown å›å¤ã€‚",
            "",
            f"**æ ¸å¿ƒè¦æ±‚**:"
        ]
        
        # âœ… æ·»åŠ å¤©æ°”æ•°æ®è¦æ±‚
        if extracted_data.get("weather_data"):
            weather_info = extracted_data["weather_data"][0]  # å–ç¬¬ä¸€æ¡
            prompt_parts.extend([
                f"1. **å¤©æ°”ä¿¡æ¯**: ä½¿ç”¨ä»¥ä¸‹çœŸå®æ•°æ®ï¼š",
                f"   - æ—¥æœŸ: {weather_info.get('date', 'N/A')}",
                f"   - ç™½å¤©å¤©æ°”: {weather_info.get('dayweather', 'N/A')}",
                f"   - å¤œé—´å¤©æ°”: {weather_info.get('nightweather', 'N/A')}",
                f"   - ç™½å¤©æ¸©åº¦: {weather_info.get('daytemp', 'N/A')}Â°C",
                f"   - å¤œé—´æ¸©åº¦: {weather_info.get('nighttemp', 'N/A')}Â°C",
                f"   âš ï¸ **ä¸è¦ä½¿ç”¨æ¨¡ç³Šçš„æ¨æµ‹æ€§è¯­è¨€ï¼Œç›´æ¥å¼•ç”¨ä¸Šè¿°çœŸå®æ•°æ®**",
                ""
            ])
        
        # âœ… æ·»åŠ  POI ä¿¡æ¯è¦æ±‚
        if extracted_data.get("pois"):
            prompt_parts.append(f"2. **æ™¯ç‚¹ä¿¡æ¯**: ä½¿ç”¨ä»¥ä¸‹æœç´¢åˆ°çš„çœŸå® POI æ•°æ®ï¼ŒåŒ…å«åç§°ã€åœ°å€ç­‰ï¼›å¯¹æ¯ä¸ªå…³é”®æ™¯ç‚¹ç”Ÿæˆç‹¬ç«‹å°èŠ‚ï¼ˆå«åç§°ä¸ºå°æ ‡é¢˜ï¼‰ï¼Œé¿å…çº¯åˆ—è¡¨å †å ã€‚")
        
        # âœ… æ·»åŠ å›¾ç‰‡è¦æ±‚ï¼ˆå†…è”æ’å…¥ï¼‰
        if extracted_data.get("poi_images"):
            # å·²æœ‰æŒ‰æ™¯ç‚¹åˆ†ç»„çš„å›¾ç‰‡
            prompt_parts.extend([
                "3. å›¾ç‰‡å±•ç¤ºï¼ˆå¿…é¡»å†…è”ï¼‰:",
                "   - å·²ä¸ºä»¥ä¸‹æ™¯ç‚¹åˆ†ç»„æ•´ç†å‡ºçœŸå®å›¾ç‰‡ URLï¼Œè¯·åœ¨å¯¹åº”æ™¯ç‚¹å°èŠ‚æœ«å°¾å†…è”æ’å…¥ 1-3 å¼ å›¾ç‰‡ï¼ˆä¼˜å…ˆä½¿ç”¨æ¯æ™¯ç‚¹å‰ 3 å¼ ï¼‰:",
            ])
            for poi_name, urls in list(extracted_data.get("poi_images", {}).items())[:8]:
                prompt_parts.append(f"   - {poi_name}:")
                for u in urls[:3]:
                    prompt_parts.append(f"     â€¢ {u}")
            prompt_parts.extend([
                "   - å›¾ç‰‡ Markdown è¯­æ³•ç¤ºä¾‹ï¼š![](https://example.com/a.jpg)",
                "   - âŒ ç»å¯¹ç¦æ­¢: ä½¿ç”¨ç¤ºä¾‹æˆ–å ä½é“¾æ¥",
                "   - âœ… æ­£ç¡®åšæ³•: æ¯ä¸ªæ™¯ç‚¹æ®µè½çš„æ–‡å­—æè¿°åç´§è·Ÿä¸€è¡Œæ’å…¥å¯¹åº”å›¾ç‰‡",
                ""
            ])
        elif extracted_data.get("images"):
            prompt_parts.extend([
                "3. **å›¾ç‰‡å±•ç¤ºï¼ˆå¿…é¡»å†…è”ï¼‰**:\n"
                "   - ä½¿ç”¨ä¸‹åˆ—çœŸå®å›¾ç‰‡ URLï¼Œå¹¶å°†å›¾ç‰‡å†…è”æ’å…¥åˆ°ç›¸åº”æ®µè½ï¼ˆä¾‹å¦‚æ¯ä¸ªæ™¯ç‚¹æ®µè½çš„æœ«å°¾ï¼‰ä¸­ï¼›ä¸è¦æŠŠå›¾ç‰‡é›†ä¸­åˆ°æ–‡æœ«ã€‚\n"
                "   - ä¼˜å…ˆä¸ºå‰ 3~5 ä¸ªå…³é”®æ™¯ç‚¹å„æ’å…¥ 1 å¼ å›¾ç‰‡ï¼›è‹¥å›¾ç‰‡æ•°ä¸è¶³ï¼Œå¯ä¸ºæœ€é‡è¦çš„æ™¯ç‚¹æ’å›¾ã€‚\n"
                "   - å›¾ç‰‡ Markdown è¯­æ³•ç¤ºä¾‹ï¼š![](https://example.com/a.jpg)\n"
                "   - ä»¥ä¸‹å¯ç”¨å›¾ç‰‡ URLï¼ˆæŒ‰é¡ºåºåŒ¹é…æ™¯ç‚¹ï¼‰ï¼š",
                *[f"   - {url}" for url in extracted_data["images"][:5]],
                "   âŒ **ç»å¯¹ç¦æ­¢**: ä½¿ç”¨ example.comã€placeholder.jpg ç­‰ç¤ºä¾‹é“¾æ¥",
                "   âœ… **æ­£ç¡®åšæ³•**: åœ¨æ¯ä¸ªæ™¯ç‚¹å°èŠ‚çš„æ–‡å­—æè¿°åç´§è·Ÿä¸€è¡Œæ’å…¥å¯¹åº”å›¾ç‰‡",
                ""
            ])
        else:
            prompt_parts.extend([
                f"3. **å›¾ç‰‡å¤„ç†**: å½“å‰æ— å¯ç”¨å›¾ç‰‡,è¯·åœ¨ç›¸å…³æ®µè½æ˜ç¡®è¯´æ˜â€œæš‚æ— å›¾ç‰‡â€ï¼Œä¸è¦ä½¿ç”¨è™šæ„é“¾æ¥",
                ""
            ])

        # æä¾› web_search çš„æŸ¥è¯¢ä¸å›¾ç‰‡åˆ—è¡¨ï¼Œä¾¿äºæ¨¡å‹åšæ›´ç²¾ç¡®ç»‘å®šï¼ˆå³ä½¿ä¸Šé¢å·²æœ‰ poi_imagesï¼‰
        if extracted_data.get("web_search_images"):
            prompt_parts.extend([
                "é™„ï¼šå›¾ç‰‡æ£€ç´¢æ˜ç»†ï¼ˆç”¨äºå¯¹é½æ™¯ç‚¹åç§°ï¼‰:",
            ])
            for pair in extracted_data.get("web_search_images", [])[:8]:
                q = pair.get("query", "")
                urls = pair.get("image_urls", [])
                prompt_parts.append(f"- æŸ¥è¯¢: {q}")
                for u in urls[:3]:
                    prompt_parts.append(f"  â€¢ {u}")
            prompt_parts.append("")
        
        # âœ… æ·»åŠ è·¯çº¿ä¿¡æ¯è¦æ±‚
        if extracted_data.get("routes"):
            route_data = extracted_data["routes"][0].get("data", {})
            if "paths" in route_data and route_data["paths"]:
                path = route_data["paths"][0]
                prompt_parts.extend([
                    f"4. **è·¯çº¿ä¿¡æ¯** (å¿…é¡»ä½¿ç”¨ç²¾ç¡®æ•°å€¼):",
                    f"   - æ€»è·ç¦»: {path.get('distance_km', 'N/A')} å…¬é‡Œ",
                    f"   - é¢„è®¡æ—¶é—´: {path.get('duration_min', 'N/A')} åˆ†é’Ÿ",
                    f"   âŒ **ç»å¯¹ç¦æ­¢**: ä½¿ç”¨â€œå¤§çº¦Xå…¬é‡Œâ€ç­‰æ¨¡ç³Šè¯­è¨€",
                    ""
                ])

        # âœ… å¦‚æœå­˜åœ¨åœ°å›¾ HTMLï¼Œè¦æ±‚åœ¨æ­£æ–‡ä¸­åˆé€‚ä½ç½®å†…è”ä¸€ä¸ªé“¾æ¥
        if extracted_data.get("map_paths"):
            prompt_parts.extend([
                f"5. **åœ°å›¾é“¾æ¥ï¼ˆæ­£æ–‡å†…è”ï¼‰**: å¦‚æœå­˜åœ¨äº¤äº’å¼åœ°å›¾ HTMLï¼Œè¯·åœ¨'è·¯çº¿'æˆ–'è¡Œç¨‹æ€»è§ˆ'æ®µè½ä¸­æ’å…¥ä¸€ä¸ªå¯ç‚¹å‡»é“¾æ¥ï¼Œæ ¼å¼ä¾‹å¦‚ï¼š[æŸ¥çœ‹äº¤äº’å¼åœ°å›¾](<map_path>)ã€‚",
                f"   å¯ç”¨åœ°å›¾è·¯å¾„ï¼ˆä»»é€‰å…¶ä¸€ï¼‰ï¼š",
                *[f"   - {p}" for p in extracted_data.get("map_paths", [])[:2]],
                ""
            ])
        
        # âœ… æ·»åŠ é€šç”¨è¦æ±‚
        prompt_parts.extend([
            f"6. å›ç­”ç”¨æˆ·çš„åŸå§‹é—®é¢˜",
            f"7. æ•´åˆæ‰€æœ‰å…³é”®ä¿¡æ¯ï¼ˆè·¯çº¿ã€è·ç¦»ã€æ—¶é—´ã€å¤©æ°”ã€æ™¯ç‚¹ç­‰ï¼‰ï¼Œå¹¶åœ¨ç›¸å…³æ®µè½å°±åœ°å†…è”æ’å…¥å›¾ç‰‡å’Œåœ°å›¾é“¾æ¥",
            f"8. ä½¿ç”¨ Markdown æ ¼å¼ï¼Œç»“æ„æ¸…æ™°ï¼ˆä½¿ç”¨äºŒçº§/ä¸‰çº§å°æ ‡é¢˜ï¼‰",
            f"9. è¯­è¨€è‡ªç„¶æµç•…ï¼ŒåƒçœŸäººå›ç­”ä¸€æ ·",
            f"10. æ–‡ä»¶è·¯å¾„å¯ç”±ç³»ç»Ÿåœ¨æ–‡æœ«è¿½åŠ ï¼›ä½†'åœ°å›¾'å…è®¸åœ¨æ­£æ–‡ä¸­å†…è”é“¾æ¥",
            "",
            f"**æœ€åæ£€æŸ¥æ¸…å•** (å‘é€å‰å¿…é¡»ç¡®è®¤):",
            f"â˜‘ï¸ æ‰€æœ‰å¤©æ°”æ•°æ®æ˜¯å¦ä½¿ç”¨äº†maps_weatherçš„çœŸå®è¿”å›å€¼?",
            f"â˜‘ï¸ æ˜¯å¦å·²åœ¨ç›¸å…³æ®µè½å†…è”æ’å…¥å›¾ç‰‡ï¼ˆä½¿ç”¨æä¾›çš„ image_urlsï¼‰?",
            f"â˜‘ï¸ æ‰€æœ‰è·ç¦»/æ—¶é—´æ˜¯å¦ä½¿ç”¨äº†è·¯çº¿å·¥å…·çš„ç²¾ç¡®è¿”å›å€¼?",
            f"â˜‘ï¸ å¦‚æœå­˜åœ¨åœ°å›¾ HTMLï¼Œæ˜¯å¦åœ¨æ­£æ–‡åˆé€‚ä½ç½®æ’å…¥äº†å¯ç‚¹å‡»é“¾æ¥?",
            f"â˜‘ï¸ æ˜¯å¦æ²¡æœ‰ä½¿ç”¨ä»»ä½•â€œå¯èƒ½â€â€œå¤§çº¦â€ç­‰ä¸ç¡®å®šè¡¨è¿°?"
        ])
        
        return "\n".join(prompt_parts)

